\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\citation{GANs}
\@writefile{toc}{\contentsline {section}{\numberline {0}Introduction}{3}{section.0}}
\citation{Deeplearning Book}
\citation{Deeplearning Book}
\citation{NIPSTutorial}
\@writefile{toc}{\contentsline {section}{\numberline {1}Recap on Feed Forward Networks}{4}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Dense Layer}{4}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Convolution Layers and Pooling Layers}{4}{subsection.1.2}}
\citation{ConditionalGAN}
\citation{WaveGAN}
\@writefile{toc}{\contentsline {section}{\numberline {2}Generative Adversarial Networks}{6}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Defining a GAN}{6}{subsection.2.1}}
\citation{NIPSTutorial}
\citation{Deeplearning Book}
\citation{BayesianComp}
\citation{BayesianComp}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Training a GAN}{7}{subsubsection.2.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Other Objectives for $G$}{7}{subsubsection.2.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Advantages over other generative models}{7}{subsubsection.2.1.3}}
\citation{GANs}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Basic theoretical results}{8}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Optimal solution for $D$ and $G$}{8}{subsubsection.2.2.1}}
\citation{WassersteinGAN}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Training a GAN}}{10}{algocf.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Convergence for Minimax GAN}{10}{subsubsection.2.2.2}}
\citation{NIPSTutorial}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Objective for MLE GAN}{11}{subsubsection.2.2.3}}
\citation{Generalisation}
\@writefile{toc}{\contentsline {section}{\numberline {3}Limitations of the Basic Results}{12}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Finite Training Data and Generalisation Theory}{12}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Limited Capacity and Neural Net Distance}{14}{subsection.3.2}}
\citation{Code}
\citation{Adam}
\@writefile{toc}{\contentsline {section}{\numberline {4}Implementation}{17}{section.4}}
\newlabel{imple}{{4}{17}{Implementation}{section.4}{}}
\newlabel{imple@cref}{{[section][4][]4}{[1][17][]17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Toy Examples with Exponential and Normal Distributions}{17}{subsection.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example of a GAN learning a normal distribution with parameters $\mu =7, \sigma = 0.7$}}{17}{figure.1}}
\newlabel{nor}{{1}{17}{Example of a GAN learning a normal distribution with parameters $\mu =7, \sigma = 0.7$}{figure.1}{}}
\newlabel{nor@cref}{{[figure][1][]1}{[1][17][]17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}MNIST DCGAN}{17}{subsection.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example of a GAN learning an exponential distribution with parameters $\mu =2$}}{18}{figure.2}}
\newlabel{exp}{{2}{18}{Example of a GAN learning an exponential distribution with parameters $\mu =2$}{figure.2}{}}
\newlabel{exp@cref}{{[figure][2][]2}{[1][17][]18}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Left: MNIST DCGAN, 1000 training iterations. Middle: 5000 training iterations. Right: MNIST Training data}}{18}{figure.3}}
\newlabel{mnistout}{{3}{18}{Left: MNIST DCGAN, 1000 training iterations. Middle: 5000 training iterations. Right: MNIST Training data}{figure.3}{}}
\newlabel{mnistout@cref}{{[figure][3][]3}{[1][17][]18}}
\citation{TrainingMethods}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Left: MNIST DCGAN Training Loss, moving average window size 10}}{19}{figure.4}}
\newlabel{DisAcc}{{4}{19}{Left: MNIST DCGAN Training Loss, moving average window size 10}{figure.4}{}}
\newlabel{DisAcc@cref}{{[figure][4][]4}{[1][18][]19}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Left: MNIST DCGAN discriminator accuracy converging to $0.5$, moving average window size 30}}{19}{figure.5}}
\newlabel{DisLoss}{{5}{19}{Left: MNIST DCGAN discriminator accuracy converging to $0.5$, moving average window size 30}{figure.5}{}}
\newlabel{DisLoss@cref}{{[figure][5][]5}{[1][18][]19}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Training Tips and Debugging}{19}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Heuristic Tips When Training}{19}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Common Failure Modes}{20}{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Mode collapse when learning two normal distributions with $\mu _1=4,\mu _2=8$ and $\sigma =0.5$}}{20}{figure.6}}
\newlabel{norhel}{{6}{20}{Mode collapse when learning two normal distributions with $\mu _1=4,\mu _2=8$ and $\sigma =0.5$}{figure.6}{}}
\newlabel{norhel@cref}{{[figure][6][]6}{[1][20][]20}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Mode collapse in the MNIST DCGAN}}{21}{figure.7}}
\newlabel{MNISThel}{{7}{21}{Mode collapse in the MNIST DCGAN}{figure.7}{}}
\newlabel{MNISThel@cref}{{[figure][7][]7}{[1][20][]21}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Heuristic Methods for Detecting Failure}{21}{subsubsection.5.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Data generated MNIST DCGAN closest to training data}}{21}{figure.8}}
\newlabel{close}{{8}{21}{Data generated MNIST DCGAN closest to training data}{figure.8}{}}
\newlabel{close@cref}{{[figure][8][]8}{[1][21][]21}}
\citation{BirthdayTest}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Interpolation between two points in MNIST DCGAN}}{22}{figure.9}}
\newlabel{interpol}{{9}{22}{Interpolation between two points in MNIST DCGAN}{figure.9}{}}
\newlabel{interpol@cref}{{[figure][9][]9}{[1][21][]22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Birthday Paradox Test}{22}{subsection.5.3}}
\newlabel{Birthday}{{7}{22}{}{theorem.7}{}}
\newlabel{Birthday@cref}{{[theorem][7][]7}{[1][22][]22}}
\citation{BirthdayAttack}
\newlabel{supportbound}{{8}{23}{}{theorem.8}{}}
\newlabel{supportbound@cref}{{[theorem][8][]8}{[1][23][]23}}
\newlabel{colbound}{{2}{23}{}{lemma.2}{}}
\newlabel{colbound@cref}{{[lemma][2][]2}{[1][23][]23}}
\citation{BirthdayTest}
\citation{GeneralisationSupp}
\citation{GameTheory}
\@writefile{toc}{\contentsline {section}{\numberline {6}Why Does the Generator Win?}{26}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Useful Definitions in Game Theory}{26}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Equilibrium for a Mixture of Generators and Discriminators}{26}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Equilibrium with a single Neural Net}{28}{subsection.6.3}}
\bibcite{Deeplearning Book}{1}
\@writefile{toc}{\contentsline {section}{\numberline {7}Appendix}{30}{section.7}}
\newlabel{IntLem}{{5}{30}{}{lemma.5}{}}
\newlabel{IntLem@cref}{{[lemma][5][]5}{[1][30][]30}}
\newlabel{worstcase}{{6}{30}{}{lemma.6}{}}
\newlabel{worstcase@cref}{{[lemma][6][]6}{[1][30][]30}}
\newlabel{laststep}{{7}{30}{}{lemma.7}{}}
\newlabel{laststep@cref}{{[lemma][7][]7}{[1][30][]30}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Appendix}{30}{section.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Code}{30}{subsection.8.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Acknowledgements}{30}{subsection.8.2}}
\bibcite{GANs}{2}
\bibcite{NIPSTutorial}{3}
\bibcite{Generalisation}{4}
\bibcite{BirthdayTest}{5}
\bibcite{WassersteinGAN}{6}
\bibcite{UnrolledGAN}{7}
\bibcite{BirthdayAttack}{8}
\bibcite{TrainingMethods}{9}
\bibcite{WaveGAN}{10}
\bibcite{GANhacks}{11}
\bibcite{StatsLearning}{12}
\bibcite{ModernStats}{13}
\bibcite{BayesianComp}{14}
\bibcite{ConvexPath}{15}
\bibcite{GeneralisationSupp}{16}
\bibcite{ConditionalGAN}{17}
\bibcite{Code}{18}
\bibcite{GameTheory}{19}
\bibcite{Adam}{20}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}References}{31}{subsection.8.3}}
